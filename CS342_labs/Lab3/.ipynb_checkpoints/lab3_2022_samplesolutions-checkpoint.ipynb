{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS342 Machine Learning\n",
    "# Lab 3: _K_-NN classification\n",
    "\n",
    "## Department of Computer Science, University of Warwick\n",
    "\n",
    "## Sample solutions\n",
    "\n",
    "## Please note: \n",
    "\n",
    "### 1. the code in this sample solution has not been optimized. This sample solution is for you to check the results you have obtained with your code.\n",
    "### 2. the code assumes the needed files are located in your working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the this lab, we will explore the use and implementation of a _K_-NN classifier and _k_-fold validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _K_-NN classification\n",
    "\n",
    " \n",
    "We will use the Diabetes dataset from the UCI Machine Learning Repository (file *diabetes.data*). Our goal is to predict if female patients will test positive for diabetes given 8 attributes, including age and blood pressure. For more details on the dataset see: https://www.kaggle.com/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset ( _diabetes.data_ ) into a Pandas data frame and standardise the attributes: for each attribute, or feature, compute its mean and standard deviation (see Lab 1) and replace each feature value by:\n",
    "\n",
    "(value - mean)/standard_deviation. \n",
    "\n",
    "Note that the last column corresponds to the class label: 1 for the positive class and 0 for the negative class. Also note that the _*.data_ file has no header. By default, Pandas will read the first row of a _.data_ file as the column name. This behaviour can be disabled by modifying the header argument. See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "\n",
    "\n",
    "#import diabetes dataset\n",
    "dataFrame = pd.read_csv('diabetes.data', header=None)\n",
    "\n",
    "\n",
    "#standardize attributes (subtract the mean and divide by the standard deviation)\n",
    "#DO NOT INCLUDE THE CLASS LABEL\n",
    "means = dataFrame[range(0,8)].mean() #Compute means\n",
    "stds = dataFrame[range(0,8)].std() #Compute std. deviation\n",
    "\n",
    "dataFrame_s = (dataFrame - means)/stds #standardise attributes\n",
    "dataFrame_s[8] = dataFrame[8] #Include the label\n",
    "# print (dataFrame_s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our two classes, i.e.,  the negative class and the positive class, write a function that takes as input your predicted targets and the true targets (i.e., the ground truth), and estimates the *Accuracy* of the classifier,\n",
    "defined as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    " Accuracy = \\frac{TP + TN}{TP + FN + FP + TN},\n",
    "\\end{equation*}\n",
    "\n",
    "where $TP$ = No. of True Positives (model predicts positive and true value is positive), $FP$ = No. of False Positives (model predicts positive and true value is negative), $TN$ = No. of True Negatives (model predicts negative and true value is negative), and $FN$ = No. of False Negatives (model predicts negative and true value is positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform _K_-NN classification using the scikit implementation (*sklearn.neighbors.KNeighborsClassifier* ) for\n",
    "_K_ = {1, 2, 3, 4, 5}. Use 10-fold cross-validation ( _sklearn.model_selection_ ) to choose the best value of _K_. Make sure to display the accuracy value of each classifier. Which is the most accurate classifier based on 10-fold cross-validation?\n",
    "\n",
    "**Hint:** You may find that the *KFold* function within *sklearn.model_selection* is useful to keep track of\n",
    "the samples assigned to each fold when performing 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7083333333333334\n",
      "0.7174479166666666\n",
      "0.74609375\n",
      "0.7330729166666666\n",
      "0.7421875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#define function to  calculate accuracy\n",
    "def calcAcc(pred,t):\n",
    "    TPTN = 0\n",
    "    total = 0\n",
    "\n",
    "    for index,val in enumerate(pred):\n",
    "        if val == t.iloc[index]:\n",
    "            TPTN += 1\n",
    "        total += 1\n",
    "        \n",
    "    return TPTN, total #return TPTN = (TP+TN) and total number of predictions. Accuracy value will be compoted based on these two values\n",
    "\n",
    "\n",
    "#define function to perform K-NN classification using k-fold validation\n",
    "def crossValidation(dataFrame,nbrs):\n",
    "    #kf contains indices of instances in each fold - use KFold to split\n",
    "    kf = KFold(10)\n",
    "    TPTN = 0\n",
    "    total = 0\n",
    "\n",
    "    #KFold returns a list containing the training instances and validation instances in each list item\n",
    "    for train, validation in kf.split(dataFrame):\n",
    "        trainingDF = dataFrame.iloc[train].copy()\n",
    "        validationDF = dataFrame.iloc[validation].copy()\n",
    "        n = kNN(n_neighbors=nbrs)\n",
    "        n.fit(trainingDF[range(0,8)],trainingDF[8])\n",
    "        \n",
    "        t1, t2 = calcAcc(n.predict(validationDF.copy()[range(0,8)]),validationDF[8]) \n",
    "\n",
    "        TPTN += t1\n",
    "        total += t2\n",
    "    \n",
    "    return TPTN/total\n",
    "\n",
    "\n",
    "\n",
    "#cross-validate with K = 1, 2, 3, 4, and 5 \n",
    "k1 = crossValidation(dataFrame_s,1)\n",
    "print (k1)\n",
    "\n",
    "k2 = crossValidation(dataFrame_s,2)\n",
    "print (k2)\n",
    "\n",
    "\n",
    "k3 = crossValidation(dataFrame_s,3)\n",
    "print (k3)\n",
    "\n",
    "\n",
    "k4 = crossValidation(dataFrame_s,4)\n",
    "print (k4)\n",
    "\n",
    "k5 = crossValidation(dataFrame_s,5)\n",
    "print (k5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
