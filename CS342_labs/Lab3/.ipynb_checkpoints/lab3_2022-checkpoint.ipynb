{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS342 Machine Learning\n",
    "# Lab 3: _K_-NN classification\n",
    "\n",
    "## Department of Computer Science, University of Warwick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the this lab, we will explore the use and implementation of a _K_-NN classifier and _k_-fold validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data files for the lab\n",
    "\n",
    "If working on one of the DCS machines, the data may be found here:\n",
    "\n",
    "```/modules/cs342/2020/lab3/data/diabetes.data ```\n",
    "\n",
    "You may load the data directly from that directory.\n",
    "\n",
    "The data are also available on the CS342 webpage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _K_-NN classification\n",
    "\n",
    " \n",
    "We will use the Diabetes dataset from the UCI Machine Learning Repository (file *diabetes.data*). Our goal is to predict if female patients will test positive for diabetes given 8 attributes, or features, including age and blood pressure. For more details on the dataset see: https://www.kaggle.com/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset ( _diabetes.data_ ) into a Pandas data frame and standardise the features: for each feature, compute its mean and standard deviation (see Lab 1) and replace each feature value by:\n",
    "\n",
    "(value - mean)/standard_deviation. \n",
    "\n",
    "Note that the last column corresponds to the class label: 1 for the positive class and 0 for the negative class. Also note that the _*.data_ file has no header. By default, Pandas will read the first row of a _.data_ file as the column name. This behaviour can be disabled by modifying the header argument. See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6  \\\n",
      "0    0.639530  0.847771  0.149543  0.906679 -0.692439  0.203880  0.468187   \n",
      "1   -0.844335 -1.122665 -0.160441  0.530556 -0.692439 -0.683976 -0.364823   \n",
      "2    1.233077  1.942458 -0.263769 -1.287373 -0.692439 -1.102537  0.604004   \n",
      "3   -0.844335 -0.997558 -0.160441  0.154433  0.123221 -0.493721 -0.920163   \n",
      "4   -1.141108  0.503727 -1.503707  0.906679  0.765337  1.408828  5.481337   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "763  1.826623 -0.622237  0.356200  1.721613  0.869464  0.115094 -0.908090   \n",
      "764 -0.547562  0.034575  0.046215  0.405181 -0.692439  0.609757 -0.398023   \n",
      "765  0.342757  0.003299  0.149543  0.154433  0.279412 -0.734711 -0.684747   \n",
      "766 -0.844335  0.159683 -0.470426 -1.287373 -0.692439 -0.240048 -0.370859   \n",
      "767 -0.844335 -0.872451  0.046215  0.655930 -0.692439 -0.201997 -0.473476   \n",
      "\n",
      "            7  8  \n",
      "0    1.425067  1  \n",
      "1   -0.190548  0  \n",
      "2   -0.105515  1  \n",
      "3   -1.040871  0  \n",
      "4   -0.020483  1  \n",
      "..        ... ..  \n",
      "763  2.530487  0  \n",
      "764 -0.530677  0  \n",
      "765 -0.275580  0  \n",
      "766  1.169970  1  \n",
      "767 -0.870806  0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "'''from __future__ import division\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#import diabetes dataset\n",
    "\n",
    "diabetes = pd.read_csv('diabetes.data', header=None)\n",
    "\n",
    "for col in diabetes.columns:\n",
    "    if (col != 8):\n",
    "        mean = diabetes[col].mean()\n",
    "        std = diabetes[col].std()\n",
    "    \n",
    "        for i in range(0, len(diabetes)):\n",
    "            diabetes.loc[i, col] = (diabetes[col].values[i] - mean)/std\n",
    "\n",
    "#print(diabetes)\n",
    "\n",
    "#standardise features (subtract the mean and divide by the standard deviation)\n",
    "#DO NOT INCLUDE THE CLASS LABEL'''\n",
    "\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "\n",
    "\n",
    "#import diabetes dataset\n",
    "dataFrame = pd.read_csv('diabetes.data', header=None)\n",
    "\n",
    "\n",
    "#standardize attributes (subtract the mean and divide by the standard deviation)\n",
    "#DO NOT INCLUDE THE CLASS LABEL\n",
    "means = dataFrame[range(0,8)].mean() #Compute means\n",
    "stds = dataFrame[range(0,8)].std() #Compute std. deviation\n",
    "\n",
    "dataFrame_s = (dataFrame - means)/stds #standardise attributes\n",
    "dataFrame_s[8] = dataFrame[8] #Include the label\n",
    "print (dataFrame_s)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our two classes, i.e.,  the negative class and the positive class, write a function that takes as input your predicted classes and the true classes (i.e., the ground truth), and estimates the *Accuracy* of the classifier, defined as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    " Accuracy = \\frac{TP + TN}{TP + FN + FP + TN},\n",
    "\\end{equation*}\n",
    "\n",
    "where $TP$ = No. of True Positives (model predicts positive and true value is positive), $FP$ = No. of False Positives (model predicts positive and true value is negative), $TN$ = No. of True Negatives (model predicts negative and true value is negative), and $FN$ = No. of False Negatives (model predicts negative and true value is positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform _K_-NN classification using the scikit implementation (*sklearn.neighbors.KNeighborsClassifier* ) for\n",
    "_K_ = {1, 2, 3, 4, 5}. Use 10-fold cross-validation ( _sklearn.model_selection_ ) to choose the best value of _K_. Make sure to display the accuracy value of each classifier. Which is the most accurate classifier based on 10-fold cross-validation?\n",
    "\n",
    "**Hint:** You may find that the *KFold* function within *sklearn.model_selection* is useful to keep track of\n",
    "the samples assigned to each fold when performing 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn.model_selection import KFold\n",
    "#define function to  calculate accuracy\n",
    "\n",
    "'''def calcAcc(pred,t):\n",
    "    TPTN = 0\n",
    "    total = 0\n",
    "    \n",
    "    for index,val in enumerate(pred):\n",
    "        if val == t.iloc(index):\n",
    "            TPTN += 1\n",
    "        total += 1\n",
    "    \n",
    "    return TPTN, total'''\n",
    "\n",
    "def calcAcc(pred,t):\n",
    "    TPTN = 0\n",
    "    total = 0\n",
    "\n",
    "    for index,val in enumerate(pred):\n",
    "        if val == t.iloc[index]:\n",
    "            TPTN += 1\n",
    "        total += 1\n",
    "        \n",
    "    return TPTN, total #return TPTN = (TP+TN) and total number of predictions. Accuracy value will be compoted based on these two values\n",
    "\n",
    "\n",
    "\n",
    "#define function to perform K-NN classification using k-fold validation\n",
    "\n",
    "def crossValidation(dataFrame, nbrs):\n",
    "    TPTN = 0\n",
    "    total = 0\n",
    "    kf = KFold(10)\n",
    "    \n",
    "    for training, validation in kf.split(dataFrame):\n",
    "        trainingDf = dataFrame.iloc[training].copy()\n",
    "        validationDf = dataFrame.iloc[validation].copy()\n",
    "        \n",
    "        n = kNN(n_neighbors=nbrs)\n",
    "        \n",
    "        n.fit(trainingDf[range(0,8)], trainingDf[8])\n",
    "        \n",
    "        t1, t2 = calcAcc(n.predict(validationDf.copy()[range(0,8)]), validationDf[8])\n",
    "        \n",
    "        TPTN+=t1\n",
    "        total+=t2\n",
    "    \n",
    "    return TPTN/total\n",
    "\n",
    "\n",
    "#cross-validate with K = 1, 2, 3, 4, and 5 \n",
    "\n",
    "k1 = crossValidation(diabetes, 1)\n",
    "print(k1)\n",
    "\n",
    "'''from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#define function to  calculate accuracy\n",
    "def calcAcc(pred,t):\n",
    "    TPTN = 0\n",
    "    total = 0\n",
    "\n",
    "    for index,val in enumerate(pred):\n",
    "        if val == t.iloc[index]:\n",
    "            TPTN += 1\n",
    "        total += 1\n",
    "        \n",
    "    return TPTN, total #return TPTN = (TP+TN) and total number of predictions. Accuracy value will be compoted based on these two values\n",
    "\n",
    "\n",
    "#define function to perform K-NN classification using k-fold validation\n",
    "def crossValidation(dataFrame,nbrs):\n",
    "    #kf contains indices of instances in each fold - use KFold to split\n",
    "    kf = KFold(10)\n",
    "    TPTN = 0\n",
    "    total = 0\n",
    "\n",
    "    #KFold returns a list containing the training instances and validation instances in each list item\n",
    "    for train, validation in kf.split(dataFrame):\n",
    "        trainingDF = dataFrame.iloc[train].copy()\n",
    "        validationDF = dataFrame.iloc[validation].copy()\n",
    "        n = kNN(n_neighbors=nbrs)\n",
    "        n.fit(trainingDF[range(0,8)],trainingDF[8])\n",
    "        \n",
    "        t1, t2 = calcAcc(n.predict(validationDF.copy()[range(0,8)]),validationDF[8]) \n",
    "\n",
    "        TPTN += t1\n",
    "        total += t2\n",
    "    \n",
    "    return TPTN/total'''\n",
    "\n",
    "\n",
    "\n",
    "#cross-validate with K = 1, 2, 3, 4, and 5 \n",
    "k1 = crossValidation(diabetes,1)\n",
    "print (k1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
